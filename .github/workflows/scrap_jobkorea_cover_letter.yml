name: Scrape Jobkorea Cover Letters

on:
  schedule:
    - cron: '0 0 * * *'  # 매일 자정에 실행
  workflow_dispatch:
    inputs:
      max_companies:
        description: '최대 회사 수'
        required: true
        default: '3'
      max_essays_per_company:
        description: '회사당 최대 에세이 수'
        required: true
        default: '5'

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install scrapy pymongo python-dotenv jsonschema

      - name: Run Scraper
        env:
          MONGO_URI: ${{ secrets.MONGO_URI }}
          MONGO_DATABASE: ${{ secrets.MONGO_DATABASE }}
        run: cd jobkorea_cover_letter | scrapy crawl jobkorea_cover_letters -a max_companies=${{ github.event.inputs.max_companies }} -a max_essays_per_company=${{ github.event.inputs.max_essays_per_company }}
