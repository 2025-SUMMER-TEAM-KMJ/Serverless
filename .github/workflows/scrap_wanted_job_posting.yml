name: Scrape Wanted Job Postings

on:
  schedule:
    - cron: '0 0 * * *'  # 매일 자정에 실행
  workflow_dispatch:
    inputs:
      mode:
        description: '스크래퍼 실행 모드'
        required: true
        default: 'create'
      max_jobs:
        description: '최대 잡 수'
        required: true
        default: '100'
      job_sort:
        description: '크롤링되는 채용 공고 순서 ( job.popularity_order | job.latest_order )'
        required: true
        default: 'job.popularity_order'

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install scrapy pymongo python-dotenv jsonschema

      - name: Run Scraper
        env:
          MONGO_URI: ${{ secrets.MONGO_URI }}
          MONGO_DATABASE: ${{ secrets.MONGO_DATABASE }}
        run: cd wanted_job_posting && scrapy crawl wanted_job_postings -a mode=${{ github.event.inputs.mode || vars.JOB_POSTING_MODE || 'create'}} -a max_jobs=${{ github.event.inputs.max_jobs || vars.JOB_POSTING_MAX_JOBS || 100 }} -a job_osrt=${{ github.event.inputs.job_sort || vars.JOB_POSTING_JOB_SORT || 'job.popularity_order'}}
